services:
  # PostgreSQL Database for LiteLLM
  # This service is optional - LiteLLM can work without a database
  # Uncomment this section if you want to use LiteLLM with database features
  # (virtual keys, spend tracking, etc.)
  postgres:
    image: postgres:15-alpine
    container_name: ollama-litellm-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-litellm}
      POSTGRES_USER: ${POSTGRES_USER:-litellm}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-litellm_password}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - ollama-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-litellm} -d ${POSTGRES_DB:-litellm}"]
      interval: 10s
      timeout: 5s
      retries: 5
    # Uncomment to expose PostgreSQL port (for debugging only)
    # ports:
    #   - "5432:5432"

  # Ollama - Local LLM Runtime
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - ollama-network
    # Uncomment for GPU support (NVIDIA)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # LiteLLM Proxy - OpenAI-compatible API Gateway
  litellm:
    image: ghcr.io/berriai/litellm:main-stable
    container_name: litellm
    restart: unless-stopped
    depends_on:
      ollama:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      # Master key for LiteLLM proxy (change this!)
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY:-sk-1234}
      # Salt key for encrypting API keys (DO NOT CHANGE after first use!)
      LITELLM_SALT_KEY: ${LITELLM_SALT_KEY:-sk-salt-1234}
      # Database URL - comment out if not using PostgreSQL
      DATABASE_URL: postgresql://${POSTGRES_USER:-litellm}:${POSTGRES_PASSWORD:-litellm_password}@postgres:5432/${POSTGRES_DB:-litellm}
      # Ollama API base URL
      OLLAMA_API_BASE: http://ollama:11434
      # Optional: Set log level
      LITELLM_LOG: ${LITELLM_LOG:-INFO}
    volumes:
      - ./litellm_config.yaml:/app/config.yaml
    networks:
      - ollama-network
    ports:
      - "${LITELLM_PORT:-4000}:4000"
    command: ["--config", "/app/config.yaml", "--port", "4000", "--num_workers", "8"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s

networks:
  ollama-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  ollama_data:
    driver: local

